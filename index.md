---
layout: default
---

### About Me

Hello! I'm **Lucky Susanto**, a research assistant at **Monash University Indonesia**. I aim to use AI for Societal benefit, such as dealing with toxicity, polarization, mis/dis/mal-information, and many more. My current research interest revolves around using concepts from mechanistic interpretability such as concept attribution to understand and create more robust models. Specifically, I aim to answer these questions:
1. How do LLMs encode higher-level concepts such as harm, morality, and safety?
2. How can we extract and edit these encodings to align LLMs after the training phase?
3. How can we enable LLMs to perform on lower-resource languages?

---

### Current Inspiration Source
[CLAIM: Mitigating Multilingual Object Hallucination in Large Vision-Language Models with Cross-Lingual Attention Intervention](https://arxiv.org/abs/2506.11073)

---

### Curriculum Vitae
[Click Here](./CV.pdf)

---

## Find Me Online

*   **Email:** `lucky[dot]susanto[at]monash[dot]edu`
*   **LinkedIn:** [Here](https://www.linkedin.com/in/lucky-susanto/)
*   **Google Scholar:** [Here](https://scholar.google.com/citations?user=PXFKZWgAAAAJ)